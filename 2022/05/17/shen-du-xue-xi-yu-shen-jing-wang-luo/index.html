<!DOCTYPE html>
<html lang='zh-CN'>

<head>
  <meta name="generator" content="Hexo 5.4.2">
  <meta charset="utf-8">
  

  <meta http-equiv='x-dns-prefetch-control' content='on' />
  <link rel='dns-prefetch' href='https://fastly.jsdelivr.net'>
  <link rel="preconnect" href="https://fastly.jsdelivr.net" crossorigin>
  <link rel='dns-prefetch' href='//unpkg.com'>
  <link rel="shortcut icon" href="https://gendml.oss-cn-hangzhou.aliyuncs.com/picgo/photo.png">
  <meta name="renderer" content="webkit">
  <meta name="force-rendering" content="webkit">
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
  <meta name="HandheldFriendly" content="True" >
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="theme-color" content="#f8f8f8">
  <title>深度学习与神经网络 - Gendml</title>

  
    <meta name="description" content="学习笔记，待更。">
<meta property="og:type" content="article">
<meta property="og:title" content="深度学习与神经网络">
<meta property="og:url" content="https://gend-max.gitee.io/2022/05/17/shen-du-xue-xi-yu-shen-jing-wang-luo/index.html">
<meta property="og:site_name" content="Gendml">
<meta property="og:description" content="学习笔记，待更。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/XuxuGood/simple-blog-cdn@master/images/site-img/loading3.gif">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/XuxuGood/simple-blog-cdn@master/images/site-img/loading3.gif">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/XuxuGood/simple-blog-cdn@master/images/site-img/loading3.gif">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/XuxuGood/simple-blog-cdn@master/images/site-img/loading3.gif">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/XuxuGood/simple-blog-cdn@master/images/site-img/loading3.gif">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/XuxuGood/simple-blog-cdn@master/images/site-img/loading3.gif">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/XuxuGood/simple-blog-cdn@master/images/site-img/loading3.gif">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/XuxuGood/simple-blog-cdn@master/images/site-img/loading3.gif">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/XuxuGood/simple-blog-cdn@master/images/site-img/loading3.gif">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/XuxuGood/simple-blog-cdn@master/images/site-img/loading3.gif">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/XuxuGood/simple-blog-cdn@master/images/site-img/loading3.gif">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/XuxuGood/simple-blog-cdn@master/images/site-img/loading3.gif">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/XuxuGood/simple-blog-cdn@master/images/site-img/loading3.gif">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/XuxuGood/simple-blog-cdn@master/images/site-img/loading3.gif">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/XuxuGood/simple-blog-cdn@master/images/site-img/loading3.gif">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/XuxuGood/simple-blog-cdn@master/images/site-img/loading3.gif">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/XuxuGood/simple-blog-cdn@master/images/site-img/loading3.gif">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/XuxuGood/simple-blog-cdn@master/images/site-img/loading3.gif">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/XuxuGood/simple-blog-cdn@master/images/site-img/loading3.gif">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/XuxuGood/simple-blog-cdn@master/images/site-img/loading3.gif">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/XuxuGood/simple-blog-cdn@master/images/site-img/loading3.gif">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/XuxuGood/simple-blog-cdn@master/images/site-img/loading3.gif">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/XuxuGood/simple-blog-cdn@master/images/site-img/loading3.gif">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/XuxuGood/simple-blog-cdn@master/images/site-img/loading3.gif">
<meta property="article:published_time" content="2022-05-17T15:35:15.000Z">
<meta property="article:modified_time" content="2022-08-19T14:16:41.199Z">
<meta property="article:author" content="Gendml">
<meta property="article:tag" content="Deep Learning">
<meta property="article:tag" content="Neural Network">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/XuxuGood/simple-blog-cdn@master/images/site-img/loading3.gif">
  
  

  <!-- feed -->
  
    <link rel="alternate" href="/atom.xml" title="Gendml" type="application/atom+xml">
  

  
    
<link rel="stylesheet" href="/css/main.css">

  

  

  
    
<link rel="stylesheet" href="https://fastly.jsdelivr.net/gh/highlightjs/cdn-release@11.5.0/build/styles/atom-one-dark.min.css">

  

  


  

<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
</head>

<body>
  




  <div class='l_body' id='start'>
    <aside class='l_left' layout='post'>
    


<header class="header">

<div class="logo-wrap"><a class="avatar" href="/about/"><div class="bg" style="opacity:0;background-image:url(https://fastly.jsdelivr.net/gh/cdn-x/placeholder@1.0.2/avatar/round/rainbow64@3x.webp);"></div><img no-lazy class="avatar" src="https://gendml.oss-cn-hangzhou.aliyuncs.com/picgo/photo.jpg" onerror="javascript:this.classList.add('error');this.src='https://fastly.jsdelivr.net/gh/cdn-x/placeholder@1.0.1/image/2659360.svg';"></a><a class="title" href="/"><div class="main">MrGendml</div><div class="sub cap">Gendml的博客空间</div></a></div>
<nav class="menu dis-select"><a class="nav-item active" href="/">文章</a><a class="nav-item" href="/wiki">专栏</a><a class="nav-item" href="/note">便笺</a><a class="nav-item" href="/about">关于我</a></nav></header>

<div class="widgets">

<div class="widget-wrap single" id="toc"><div class="widget-header cap dis-select"><span class="name">本文目录</span></div><div class="widget-body fs14"><div class="doc-tree active"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-1%E6%A2%AF%E5%BA%A6"><span class="toc-text">1.1梯度</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-2%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95%E6%80%9D%E8%B7%AF"><span class="toc-text">1.2梯度下降法思路</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-1%E5%B9%BF%E6%92%AD%E6%A1%88%E4%BE%8B"><span class="toc-text">2.1广播案例</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-2Numpy%E4%B8%AD%E7%9A%84%E5%B9%BF%E6%92%AD%E6%9C%BA%E5%88%B6"><span class="toc-text">2.2Numpy中的广播机制</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-1%E4%BB%80%E4%B9%88%E6%98%AF%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%EF%BC%9F"><span class="toc-text">3.1什么是线性回归？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-2%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95"><span class="toc-text">3.2最小二乘法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-1%E4%BB%80%E4%B9%88%E6%98%AF%E4%BC%BC%E7%84%B6%E5%87%BD%E6%95%B0%EF%BC%9F"><span class="toc-text">4.1什么是似然函数？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-2%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1"><span class="toc-text">4.2最大似然估计</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-3%E7%A6%BB%E6%95%A3%E5%9E%8B%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E7%9A%84%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1"><span class="toc-text">4.3离散型随机变量的最大似然估计</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-4%E8%BF%9E%E7%BB%AD%E5%9E%8B%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E7%9A%84%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1"><span class="toc-text">4.4连续型随机变量的最大似然估计</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-1Logistic%E5%9B%9E%E5%BD%92"><span class="toc-text">5.1Logistic回归</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-2Logistic%E5%9B%9E%E5%BD%92%E5%86%8D%E5%9C%A8%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%BA%94%E7%94%A8"><span class="toc-text">5.2Logistic回归再在神经网络的应用</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-3%E6%8E%A8%E5%AF%BC%E8%BF%87%E7%A8%8B"><span class="toc-text">5.3推导过程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-1Sigmoid%E5%87%BD%E6%95%B0"><span class="toc-text">6.1Sigmoid函数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-2tanh%E5%87%BD%E6%95%B0"><span class="toc-text">6.2tanh函数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-3ReLu%E5%87%BD%E6%95%B0"><span class="toc-text">6.3ReLu函数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-4Leaky-ReLu%E5%87%BD%E6%95%B0"><span class="toc-text">6.4Leaky ReLu函数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B1%82%E5%92%8C%E5%85%AC%E5%BC%8F"><span class="toc-text">求和公式</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E5%AD%97"><span class="toc-text">数字</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%9B%86%E5%90%88%E8%AE%BA"><span class="toc-text">集合论</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%87%BD%E6%95%B0%E5%92%8C%E8%BF%90%E7%AE%97%E7%AC%A6"><span class="toc-text">函数和运算符</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BE%AE%E7%A7%AF%E5%88%86"><span class="toc-text">微积分</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A6%82%E7%8E%87%E4%B8%8E%E4%BF%A1%E6%81%AF%E8%AE%BA"><span class="toc-text">概率与信息论</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%8D%E6%9D%82%E5%BA%A6"><span class="toc-text">复杂度</span></a></li></ol></div></div></div>

<div class="widget-wrap" id="recent"><div class="widget-header cap dis-select"><span class="name">最近更新</span><a class="cap-action" id="rss" title="Subscribe" href="/atom.xml"><svg class="icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="8938"><path d="M800.966 947.251c0-404.522-320.872-732.448-716.69-732.448V62.785c477.972 0 865.44 395.987 865.44 884.466h-148.75z m-162.273 0h-148.74c0-228.98-181.628-414.598-405.678-414.598v-152.01c306.205 0 554.418 253.68 554.418 566.608z m-446.24-221.12c59.748 0 108.189 49.503 108.189 110.557 0 61.063-48.44 110.563-108.188 110.563-59.747 0-108.18-49.5-108.18-110.563 0-61.054 48.433-110.556 108.18-110.556z" p-id="8939"></path></svg></a></div><div class="widget-body fs14"><div class="more-item"><a class="title" href="/2022/08/07/docker/">Docker</a></div><div class="more-item"><a class="title" href="/2022/05/17/linux/">Linux</a></div><div class="more-item"><a class="title" href="/2022/09/23/ecnuinterview/">ECNUInterview</a></div><div class="more-item"><a class="title" href="/2022/08/07/node/">Node.js</a></div><div class="more-item"><a class="title" href="/2022/05/17/shu-mei-pai-chang-yong-ming-ling/">树莓派常用命令</a></div></div></div>
</div>
<footer class="footer dis-select"><div class="social-wrap"><a class="social" href="https://github.com/GenD-max" target="_blank" rel="external nofollow noopener noreferrer"><img src="https://fastly.jsdelivr.net/gh/cdn-x/placeholder@1.0.3/social/08a41b181ce68.svg"/></a><a class="social" href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=2457870242" target="_blank" rel="external nofollow noopener noreferrer"><img src="https://gendml.oss-cn-hangzhou.aliyuncs.com/picgo/QQ.svg"/></a><a class="social" href="mailto:dmlgg0425@gmail.com" rel="noopener noreferrer"><img src="https://cdn.jsdelivr.net/gh/cdn-x/placeholder@1.0.3/social/a1b00e20f425d.svg"/></a></div></footer>

    </aside>
    <div class='l_main'>
      

      

    
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
          tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            processEscapes: true
          }
        });
      </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
            tex2jax: {
              skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
            }
          });
      </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
              var all = MathJax.Hub.getAllJax(), i;
              for(i=0; i < all.length; i += 1) {
                  all[i].SourceElement().parentNode.className += ' has-jax';
              }
          });
      </script>

    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.6/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>




<div class="bread-nav fs12"><div id="breadcrumb"><a class="cap breadcrumb" href="/">主页</a><span class="sep"></span><a class="cap breadcrumb" href="/">文章</a><span class="sep"></span><a class="cap breadcrumb-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></div><div id="post-meta">发布于&nbsp;<time datetime="2022-05-17T15:35:15.000Z">2022-05-17</time></div></div>

<article class='content md post reveal'>
<h1 class="article-title"><span>深度学习与神经网络</span></h1>
<h1 id="1、梯度下降法"><a href="#1、梯度下降法" class="headerlink" title="1、梯度下降法"></a>1、梯度下降法</h1><h2 id="1-1梯度"><a href="#1-1梯度" class="headerlink" title="1.1梯度"></a>1.1梯度</h2><p>梯度是函数增长最快的方向，梯度的模为这一方向的变化率。</p>
<p>对于一元函数求梯度，公式为:<br>$$<br>\frac{d y}{d x}=f^{\prime}(x)=\lim _{\Delta x \rightarrow 0} \frac{\mathrm{f}(\mathrm{x}+\Delta x)-f(x)}{\Delta x}<br>$$<br>很显然，该函数的梯度为一条<strong>切线</strong>。</p>
<img src="https://cdn.jsdelivr.net/gh/XuxuGood/simple-blog-cdn@master/images/site-img/loading3.gif" data-original="https://gendml.oss-cn-hangzhou.aliyuncs.com/picgo/image-20220326213334951.png" alt="image-20220326213334951" style="zoom: 33%;">

<p>而对于多维函数，比如f(x,y)，此函数的梯度为一个<strong>切面</strong>。</p>
<img src="https://cdn.jsdelivr.net/gh/XuxuGood/simple-blog-cdn@master/images/site-img/loading3.gif" data-original="https://gendml.oss-cn-hangzhou.aliyuncs.com/picgo/image-20220326213602608.png" alt="image-20220326213602608" style="zoom:33%;">

<p>如果再进行维度拓展，将无法进行求解，科学家通过引入<strong>偏导</strong>，求解梯度：</p>
<h2 id="1-2梯度下降法思路"><a href="#1-2梯度下降法思路" class="headerlink" title="1.2梯度下降法思路"></a>1.2梯度下降法思路</h2><p>找到函数的梯度，在此方向取负梯度，函数下降的最快，进而找到函数的最小值，一般用于求解损失函数的最小值，优化模型。</p>
<h1 id="2、Python中的广播"><a href="#2、Python中的广播" class="headerlink" title="2、Python中的广播"></a>2、Python中的广播</h1><h2 id="2-1广播案例"><a href="#2-1广播案例" class="headerlink" title="2.1广播案例"></a>2.1广播案例</h2><img src="https://cdn.jsdelivr.net/gh/XuxuGood/simple-blog-cdn@master/images/site-img/loading3.gif" data-original="https://gendml.oss-cn-hangzhou.aliyuncs.com/picgo/image-20220329214513085.png" alt="image-20220329214513085" style="zoom: 33%;">

<p>当两个矩阵相加，在不符合线性代数矩阵运算时，矩阵会自动扩展结构，然后执行运算</p>
<h2 id="2-2Numpy中的广播机制"><a href="#2-2Numpy中的广播机制" class="headerlink" title="2.2Numpy中的广播机制"></a>2.2Numpy中的广播机制</h2><p>广播(Broadcast)是 numpy 对不同形状(shape)的数组进行数值计算的方式， 对数组的算术运算通常在相应的元素上进行。</p>
<p>如果两个数组 a 和 b 形状相同，即满足 <strong>a.shape == b.shape</strong>，那么 a*b 的结果就是 a 与 b 数组对应位相乘。这要求维数相同，且各维度的长度相同。</p>
<p>实例:</p>
<pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np 
 
a = np.array([[ <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],
           [<span class="hljs-number">10</span>,<span class="hljs-number">10</span>,<span class="hljs-number">10</span>],
           [<span class="hljs-number">20</span>,<span class="hljs-number">20</span>,<span class="hljs-number">20</span>],
           [<span class="hljs-number">30</span>,<span class="hljs-number">30</span>,<span class="hljs-number">30</span>]])
b = np.array([<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>])
<span class="hljs-built_in">print</span>(a + b)</code></pre>

<p>输出结果：</p>
<pre><code class="hljs python">[[ <span class="hljs-number">1</span>  <span class="hljs-number">2</span>  <span class="hljs-number">3</span>]
 [<span class="hljs-number">11</span> <span class="hljs-number">12</span> <span class="hljs-number">13</span>]
 [<span class="hljs-number">21</span> <span class="hljs-number">22</span> <span class="hljs-number">23</span>]
 [<span class="hljs-number">31</span> <span class="hljs-number">32</span> <span class="hljs-number">33</span>]]</code></pre>

<p>下面的图片展示了数组 b 如何通过广播来与数组 a 兼容。</p>
<p><img src="https://cdn.jsdelivr.net/gh/XuxuGood/simple-blog-cdn@master/images/site-img/loading3.gif" data-original="https://gendml.oss-cn-hangzhou.aliyuncs.com/picgo/image0020619.gif" alt="img"></p>
<h1 id="3、最小二乘法"><a href="#3、最小二乘法" class="headerlink" title="3、最小二乘法"></a>3、最小二乘法</h1><h2 id="3-1什么是线性回归？"><a href="#3-1什么是线性回归？" class="headerlink" title="3.1什么是线性回归？"></a>3.1什么是线性回归？</h2><p>比如，在二维空间中，线性回归就是要找一条直线，并且让这条直线尽可能拟合图中的数据点</p>
<img src="https://cdn.jsdelivr.net/gh/XuxuGood/simple-blog-cdn@master/images/site-img/loading3.gif" data-original="https://gendml.oss-cn-hangzhou.aliyuncs.com/picgo/image-20220330160837326.png" alt="image-20220330160837326" style="zoom: 67%;">

<img src="https://cdn.jsdelivr.net/gh/XuxuGood/simple-blog-cdn@master/images/site-img/loading3.gif" data-original="https://gendml.oss-cn-hangzhou.aliyuncs.com/picgo/image-20220330160919509.png" alt="image-20220330160919509" style="zoom:67%;">

<p>每条红色竖线是预测数据到真实数据的差距（误差），称为欧氏距离，然后将这些误差加起来，就得到线性回归的损失函数。<br>$$<br>\sum_{i=0}^{m} (y^{(i)} - \hat{y}  ^{(i)} )^{^{2} }<br>$$</p>
<h2 id="3-2最小二乘法"><a href="#3-2最小二乘法" class="headerlink" title="3.2最小二乘法"></a>3.2最小二乘法</h2><p><a target="_blank" rel="noopener" href="https://www.zhihu.com/topic/19668117/intro">见知乎专栏</a></p>
<p><strong>在实际观测时，考虑到观测值带有偶然误差，总是作多余观测</strong>。</p>
<p><img src="https://cdn.jsdelivr.net/gh/XuxuGood/simple-blog-cdn@master/images/site-img/loading3.gif" data-original="https://gendml.oss-cn-hangzhou.aliyuncs.com/picgo/20220613001311.png"></p>
<h1 id="4、最大似然估计"><a href="#4、最大似然估计" class="headerlink" title="4、最大似然估计"></a>4、最大似然估计</h1><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/55791843">见知乎专栏</a></p>
<p>最大似然估计可以说是应用非常广泛的一种参数估计的方法。它的原理也很简单：利用已知的样本，找出最有可能生成该样本的参数。</p>
<h2 id="4-1什么是似然函数？"><a href="#4-1什么是似然函数？" class="headerlink" title="4.1什么是似然函数？"></a>4.1什么是似然函数？</h2><p><img src="https://cdn.jsdelivr.net/gh/XuxuGood/simple-blog-cdn@master/images/site-img/loading3.gif" data-original="https://gendml.oss-cn-hangzhou.aliyuncs.com/picgo/20220613000609.png"></p>
<h2 id="4-2最大似然估计"><a href="#4-2最大似然估计" class="headerlink" title="4.2最大似然估计"></a>4.2最大似然估计</h2><p><img src="https://cdn.jsdelivr.net/gh/XuxuGood/simple-blog-cdn@master/images/site-img/loading3.gif" data-original="https://gendml.oss-cn-hangzhou.aliyuncs.com/picgo/20220613000628.png"></p>
<h2 id="4-3离散型随机变量的最大似然估计"><a href="#4-3离散型随机变量的最大似然估计" class="headerlink" title="4.3离散型随机变量的最大似然估计"></a>4.3离散型随机变量的最大似然估计</h2><p><img src="https://cdn.jsdelivr.net/gh/XuxuGood/simple-blog-cdn@master/images/site-img/loading3.gif" data-original="https://gendml.oss-cn-hangzhou.aliyuncs.com/picgo/20220613001346.png"></p>
<p><img src="https://cdn.jsdelivr.net/gh/XuxuGood/simple-blog-cdn@master/images/site-img/loading3.gif" data-original="https://gendml.oss-cn-hangzhou.aliyuncs.com/picgo/20220613001434.png"><br>$$<br>C_{n}^{k} = \frac{n!}{k!(n-k)!}是二项式系数，我们希望有k次成功(p)和n−k次失败(1 −p)，并且，k次成功可以在n次试验的任何地方出现，而把k次成功分布在n次试验中共有C_{n}^{k}个不同的方法。<br>$$</p>
<h2 id="4-4连续型随机变量的最大似然估计"><a href="#4-4连续型随机变量的最大似然估计" class="headerlink" title="4.4连续型随机变量的最大似然估计"></a>4.4连续型随机变量的最大似然估计</h2><p><img src="https://cdn.jsdelivr.net/gh/XuxuGood/simple-blog-cdn@master/images/site-img/loading3.gif" data-original="https://gendml.oss-cn-hangzhou.aliyuncs.com/picgo/20220613001521.png"></p>
<p><img src="https://cdn.jsdelivr.net/gh/XuxuGood/simple-blog-cdn@master/images/site-img/loading3.gif" data-original="https://gendml.oss-cn-hangzhou.aliyuncs.com/picgo/v2-0012043fca529a0c5a88a1425ccf48dc_720w.jpg" alt="img"></p>
<p><img src="https://cdn.jsdelivr.net/gh/XuxuGood/simple-blog-cdn@master/images/site-img/loading3.gif" data-original="https://gendml.oss-cn-hangzhou.aliyuncs.com/picgo/20220613001655.png"></p>
<p><img src="https://cdn.jsdelivr.net/gh/XuxuGood/simple-blog-cdn@master/images/site-img/loading3.gif" data-original="https://gendml.oss-cn-hangzhou.aliyuncs.com/picgo/v2-4acb983eefed903c9da719cef00a7745_720w.jpg" alt="img"></p>
<h1 id="5、Logistic回归"><a href="#5、Logistic回归" class="headerlink" title="5、Logistic回归"></a>5、Logistic回归</h1><h2 id="5-1Logistic回归"><a href="#5-1Logistic回归" class="headerlink" title="5.1Logistic回归"></a>5.1Logistic回归</h2><p>如下图所示，计算节点值z，再通过激活函数sigmoid()求出a，a为到该节点的输出，如下图。</p>
<img src="https://cdn.jsdelivr.net/gh/XuxuGood/simple-blog-cdn@master/images/site-img/loading3.gif" data-original="https://gendml.oss-cn-hangzhou.aliyuncs.com/picgo/image-20220401173054150.png" alt="image-20220401173054150" style="zoom: 50%;">

<h2 id="5-2Logistic回归再在神经网络的应用"><a href="#5-2Logistic回归再在神经网络的应用" class="headerlink" title="5.2Logistic回归再在神经网络的应用"></a>5.2Logistic回归再在神经网络的应用</h2><p>神经网络正向传播中执行了很多次类似Logistic回归的操作，如下图所示，每个节点执行了一次Logistic回归，舍弃for循环，通过矩阵运算快速计算出z（用z[1]表示）和a（用a[1]表示）。</p>
<p><img src="https://cdn.jsdelivr.net/gh/XuxuGood/simple-blog-cdn@master/images/site-img/loading3.gif" data-original="https://gendml.oss-cn-hangzhou.aliyuncs.com/picgo/image-20220401174013810.png" alt="image-20220401174013810"></p>
<p>计算完隐藏层节点的值后，再作为输入计算输出层的值。</p>
<p><img src="https://cdn.jsdelivr.net/gh/XuxuGood/simple-blog-cdn@master/images/site-img/loading3.gif" data-original="https://gendml.oss-cn-hangzhou.aliyuncs.com/picgo/image-20220401175106812.png" alt="image-20220401175106812"></p>
<h2 id="5-3推导过程"><a href="#5-3推导过程" class="headerlink" title="5.3推导过程"></a>5.3推导过程</h2><p>见：<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1aE411o7qd?p=17">BiliBili讲解</a></p>
<p><img src="https://cdn.jsdelivr.net/gh/XuxuGood/simple-blog-cdn@master/images/site-img/loading3.gif" data-original="https://gendml.oss-cn-hangzhou.aliyuncs.com/picgo/image-20220330224031997.png" alt="image-20220330224031997"></p>
<p>涉及到0/1的二分类问题，通过Sigmoid函数表示出1和0的发生概率，使用最大似然估计法，最后求导得出使得概率最大的参数值。</p>
<h1 id="6、激活函数"><a href="#6、激活函数" class="headerlink" title="6、激活函数"></a>6、激活函数</h1><p>在构建神经网络的时候，如何选择激活函数？此过程往往有很多的参数选择，通过测试的方法，找到一个最适合自己的激活函数，调参。</p>
<h2 id="6-1Sigmoid函数"><a href="#6-1Sigmoid函数" class="headerlink" title="6.1Sigmoid函数"></a>6.1Sigmoid函数</h2><p>除非用在二元分类的输出层，不然绝对不要用。</p>
<img src="https://cdn.jsdelivr.net/gh/XuxuGood/simple-blog-cdn@master/images/site-img/loading3.gif" data-original="https://gendml.oss-cn-hangzhou.aliyuncs.com/picgo/image-20220401212246481.png" alt="image-20220401212246481" style="zoom: 50%;">

<h2 id="6-2tanh函数"><a href="#6-2tanh函数" class="headerlink" title="6.2tanh函数"></a>6.2tanh函数</h2><p>几乎在所有场合都适用。</p>
<img src="https://cdn.jsdelivr.net/gh/XuxuGood/simple-blog-cdn@master/images/site-img/loading3.gif" data-original="https://gendml.oss-cn-hangzhou.aliyuncs.com/picgo/image-20220401212426016.png" alt="image-20220401212426016" style="zoom: 50%;">

<h2 id="6-3ReLu函数"><a href="#6-3ReLu函数" class="headerlink" title="6.3ReLu函数"></a>6.3ReLu函数</h2><p>不知道用哪个的时候，用这个</p>
<img src="https://cdn.jsdelivr.net/gh/XuxuGood/simple-blog-cdn@master/images/site-img/loading3.gif" data-original="https://gendml.oss-cn-hangzhou.aliyuncs.com/picgo/image-20220401212550526.png" alt="image-20220401212550526" style="zoom:50%;">

<h2 id="6-4Leaky-ReLu函数"><a href="#6-4Leaky-ReLu函数" class="headerlink" title="6.4Leaky ReLu函数"></a>6.4Leaky ReLu函数</h2><img src="https://cdn.jsdelivr.net/gh/XuxuGood/simple-blog-cdn@master/images/site-img/loading3.gif" data-original="https://gendml.oss-cn-hangzhou.aliyuncs.com/picgo/image-20220401212839258.png" alt="image-20220401212839258" style="zoom:50%;">

<h1 id="附：数学公式"><a href="#附：数学公式" class="headerlink" title="附：数学公式"></a>附：数学公式</h1><h2 id="求和公式"><a href="#求和公式" class="headerlink" title="求和公式"></a>求和公式</h2><img src="https://cdn.jsdelivr.net/gh/XuxuGood/simple-blog-cdn@master/images/site-img/loading3.gif" data-original="https://gendml.oss-cn-hangzhou.aliyuncs.com/picgo/image-20211227103823765.png" alt="image-20211227103823765" style="zoom: 80%;">

<h1 id="附：数学符号"><a href="#附：数学符号" class="headerlink" title="附：数学符号"></a>附：数学符号</h1><h2 id="数字"><a href="#数字" class="headerlink" title="数字"></a>数字</h2><ul>
<li>x：标量</li>
<li>x：向量</li>
<li>X：矩阵</li>
<li>X：张量</li>
<li>I：单位矩阵</li>
<li>xi, [x]i：向量x第i个元素</li>
<li>xij, [X]ij：矩阵X第i行第j列的元素</li>
</ul>
<h2 id="集合论"><a href="#集合论" class="headerlink" title="集合论"></a>集合论</h2><ul>
<li>X: 集合</li>
<li>Z: 整数集合</li>
<li>R: 实数集合</li>
<li>Rn: n维实数向量</li>
<li>Ra×b: 包含a行和b列的实数矩阵</li>
<li>A∪B: 集合A和B的并集</li>
<li>A∩B：集合A和B的交集</li>
<li>A∖B：集合A与集合B相减，B关于A的相对补集</li>
</ul>
<h2 id="函数和运算符"><a href="#函数和运算符" class="headerlink" title="函数和运算符"></a>函数和运算符</h2><ul>
<li>f(⋅)：函数</li>
<li>log⁡(⋅)：自然对数</li>
<li>exp⁡(⋅): 指数函数</li>
<li>1X: 指示函数</li>
<li>(⋅)⊤: 向量或矩阵的转置</li>
<li>X−1: 矩阵的逆</li>
<li>⊙: 按元素相乘</li>
<li>[⋅,⋅]：连结</li>
<li>|X|：集合的基数</li>
<li>‖⋅‖p: ：Lp 正则</li>
<li>‖⋅‖: L2 正则</li>
<li>⟨x,y⟩：向量x和y的点积</li>
<li>∑: 连加</li>
<li>∏: 连乘</li>
<li>=def：定义</li>
</ul>
<h2 id="微积分"><a href="#微积分" class="headerlink" title="微积分"></a>微积分</h2><ul>
<li>dydx：y关于x的导数</li>
<li>∂y∂x：y关于x的偏导数</li>
<li>∇xy：y关于x的梯度</li>
<li>∫abf(x)dx: f在a到b区间上关于x的定积分</li>
<li>∫f(x)dx: f关于x的不定积分</li>
</ul>
<h2 id="概率与信息论"><a href="#概率与信息论" class="headerlink" title="概率与信息论"></a>概率与信息论</h2><ul>
<li>P(⋅)：概率分布</li>
<li>z∼P: 随机变量z具有概率分布P</li>
<li>P(X∣Y)：X∣Y的条件概率</li>
<li>p(x): 概率密度函数</li>
<li>Ex[f(x)]: 函数f对x的数学期望</li>
<li>X⊥Y: 随机变量X和Y是独立的</li>
<li>X⊥Y∣Z: 随机变量X和Y在给定随机变量Z的条件下是独立的</li>
<li>Var(X): 随机变量X的方差</li>
<li>σX: 随机变量X的标准差</li>
<li>Cov(X,Y): 随机变量X和Y的协方差</li>
<li>ρ(X,Y): 随机变量X和Y的相关性</li>
<li>H(X): 随机变量X的熵</li>
<li>DKL(P‖Q): P和Q的KL-散度</li>
</ul>
<h2 id="复杂度"><a href="#复杂度" class="headerlink" title="复杂度"></a>复杂度</h2><ul>
<li>O：大O标记</li>
</ul>


<div class="article-footer reveal fs14"><section id="license"><div class="header"><span>许可协议</span></div><div class="body"><p>本文采用 <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">署名-非商业性使用-相同方式共享 4.0 国际</a> 许可协议，转载请注明出处。</p>
</div></section><section id="share"><div class="header"><span>分享文章</span></div><div class="body"><div class="link"><input class="copy-area" readonly="true" id="copy-link" value="https://gend-max.gitee.io/2022/05/17/shen-du-xue-xi-yu-shen-jing-wang-luo/" /></div><div class="social-wrap dis-select"><a class="social share-item wechat" onclick="util.toggle(&quot;qrcode-wechat&quot)"><img src="https://fastly.jsdelivr.net/gh/cdn-x/placeholder@1.0.1/social/b32ef3da1162a.svg"/></a><a class="social share-item weibo" target="_blank" rel="external nofollow noopener noreferrer" href="https://service.weibo.com/share/share.php?url=https://gend-max.gitee.io/2022/05/17/shen-du-xue-xi-yu-shen-jing-wang-luo/&title=深度学习与神经网络 - Gendml&summary=学习笔记，待更。"><img src="https://fastly.jsdelivr.net/gh/cdn-x/placeholder@1.0.1/social/80c07e4dbb303.svg"/></a><a class="social share-item email" href="mailto:?subject=深度学习与神经网络 - Gendml&amp;body=https://gend-max.gitee.io/2022/05/17/shen-du-xue-xi-yu-shen-jing-wang-luo/"><img src="https://fastly.jsdelivr.net/gh/cdn-x/placeholder@1.0.1/social/a1b00e20f425d.svg"/></a><a class="social share-item link" onclick="util.copy(&quot;copy-link&quot;, &quot;复制成功&quot;)"><img src="https://fastly.jsdelivr.net/gh/cdn-x/placeholder@1.0.1/social/8411ed322ced6.svg"/></a></div><div class="qrcode" id="qrcode-wechat" style="visibility:hidden;height:0"><img src="https://api.qrserver.com/v1/create-qr-code/?size=256x256&data=https://gend-max.gitee.io/2022/05/17/shen-du-xue-xi-yu-shen-jing-wang-luo/index.html"/></div></div></section></div>

</article>

<div class="related-wrap reveal" id="read-next"><section class="header cap theme"><span>接下来阅读</span></section><section class="body fs14"><a id="next" href="/2022/05/17/springboot/">SpringBoot<span class="note">较早</span></a><div class="line"></div><a id="prev" href="/2022/05/17/shu-mei-pai-chang-yong-ming-ling/">树莓派常用命令<span class="note">较新</span></a></section></div>


<div class="related-wrap reveal" id="related-posts"></div>



  <div class='related-wrap md reveal' id="comments">
    <div class='cmt-title cap theme'>
      快来参与讨论吧
    </div>
    <div class='cmt-body beaudar'>
      

<svg class="loading" style="vertical-align: middle;fill: currentColor;overflow: hidden;" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="2709"><path d="M832 512c0-176-144-320-320-320V128c211.2 0 384 172.8 384 384h-64zM192 512c0 176 144 320 320 320v64C300.8 896 128 723.2 128 512h64z" p-id="2710"></path></svg>

<div id="beaudar" repo="GenD-max/Beaudar" issue-term="pathname" theme="dark-blue" label="Blog Comments" input-position="top" comment-order="desc" keep-theme="true" loading="true" branch="master"></div>

    </div>
  </div>



      
<footer class="page-footer reveal fs12"><hr><div class="sitemap"><div class="sitemap-group"><span class="fs14">博客</span><a href="/">文章</a><a href="/wiki">专栏</a><a href="/note">便笺</a></div><div class="sitemap-group"><span class="fs14">社交</span><a href="/about">留言板</a></div><div class="sitemap-group"><span class="fs14">更多</span><a href="/about">关于我</a><a target="_blank" rel="noopener" href="https://github.com/GenD-max">GitHub</a></div></div><div class="text"><p>本博客所有文章除特别声明外，均采用 <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> 许可协议，转载请注明出处。</p>
<p>本站由 <a href="https://gend-max.gitee.io/">@Gendml</a> 创建，使用 <a target="_blank" rel="noopener" href="https://github.com/xaoxuu/hexo-theme-stellar/tree/1.8.0" title="v1.8.0">Stellar</a> 作为主题。</p>
</div></footer>

      <div class='float-panel mobile-only blur' style='display:none'>
  <button type='button' class='sidebar-toggle mobile' onclick='sidebar.toggle()'>
    <svg class="icon" style="width: 1em; height: 1em;vertical-align: middle;fill: currentColor;overflow: hidden;" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="15301"><path d="M566.407 808.3c26.9-0.1 49.3-20.8 51.6-47.6-1.9-27.7-23.9-49.7-51.6-51.6h-412.6c-28.2-1.4-52.6 19.5-55.5 47.6 2.3 26.8 24.6 47.5 51.6 47.6h416.5v4z m309.3-249.9c26.9-0.1 49.3-20.8 51.6-47.6-2.2-26.8-24.6-47.5-51.6-47.6h-721.9c-27.7-2.8-52.5 17.4-55.3 45.1-0.1 0.8-0.1 1.7-0.2 2.5 0.9 27.2 23.6 48.5 50.7 47.6H875.707z m-103.1-245.9c26.9-0.1 49.3-20.8 51.6-47.6-0.4-28.3-23.2-51.1-51.5-51.6h-618.9c-29.5-1.1-54.3 21.9-55.5 51.4v0.2c1.4 27.8 25.2 49.2 53 47.8 0.8 0 1.7-0.1 2.5-0.2h618.8z" p-id="15302"></path><path d="M566.407 808.3c26.9-0.1 49.3-20.8 51.6-47.6-1.9-27.7-23.9-49.7-51.6-51.6h-412.6c-28.2-1.4-52.6 19.5-55.5 47.6 1.9 27.7 23.9 49.7 51.6 51.6h416.5z m309.3-249.9c26.9-0.1 49.3-20.8 51.6-47.6-2.2-26.8-24.6-47.5-51.6-47.6h-721.9c-27.7-2.8-52.5 17.4-55.3 45.1-0.1 0.8-0.1 1.7-0.2 2.5 0.9 27.2 23.6 48.5 50.7 47.6H875.707z m-103.1-245.9c26.9-0.1 49.3-20.8 51.6-47.6-0.4-28.3-23.2-51.1-51.5-51.6h-618.9c-29.5-1.1-54.3 21.9-55.5 51.4v0.2c1.4 27.8 25.2 49.2 53 47.8 0.8 0 1.7-0.1 2.5-0.2h618.8z" p-id="15303"></path></svg>
  </button>
</div>

    </div>
  </div>
  <div class='scripts'>
    <script type="text/javascript">
  stellar = {
    // 懒加载 css https://github.com/filamentgroup/loadCSS
    loadCSS: (href, before, media, attributes) => {
      var doc = window.document;
      var ss = doc.createElement("link");
      var ref;
      if (before) {
        ref = before;
      } else {
        var refs = (doc.body || doc.getElementsByTagName("head")[0]).childNodes;
        ref = refs[refs.length - 1];
      }
      var sheets = doc.styleSheets;
      if (attributes) {
        for (var attributeName in attributes) {
          if (attributes.hasOwnProperty(attributeName)) {
            ss.setAttribute(attributeName, attributes[attributeName]);
          }
        }
      }
      ss.rel = "stylesheet";
      ss.href = href;
      ss.media = "only x";
      function ready(cb) {
        if (doc.body) {
          return cb();
        }
        setTimeout(function () {
          ready(cb);
        });
      }
      ready(function () {
        ref.parentNode.insertBefore(ss, before ? ref : ref.nextSibling);
      });
      var onloadcssdefined = function (cb) {
        var resolvedHref = ss.href;
        var i = sheets.length;
        while (i--) {
          if (sheets[i].href === resolvedHref) {
            return cb();
          }
        }
        setTimeout(function () {
          onloadcssdefined(cb);
        });
      };
      function loadCB() {
        if (ss.addEventListener) {
          ss.removeEventListener("load", loadCB);
        }
        ss.media = media || "all";
      }
      if (ss.addEventListener) {
        ss.addEventListener("load", loadCB);
      }
      ss.onloadcssdefined = onloadcssdefined;
      onloadcssdefined(loadCB);
      return ss;
    },

    // 从 butterfly 和 volantis 获得灵感
    loadScript: (src, opt) => new Promise((resolve, reject) => {
      var script = document.createElement('script');
      script.src = src;
      if (opt) {
        for (let key of Object.keys(opt)) {
          script[key] = opt[key]
        }
      } else {
        // 默认异步，如果需要同步，第二个参数传入 {} 即可
        script.async = true
      }
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    }),

    // https://github.com/jerryc127/hexo-theme-butterfly
    jQuery: (fn) => {
      if (typeof jQuery === 'undefined') {
        stellar.loadScript(stellar.plugins.jQuery).then(fn)
      } else {
        fn()
      }
    }
  };
  stellar.github = 'https://github.com/xaoxuu/hexo-theme-stellar/tree/1.8.0';
  stellar.config = {
    date_suffix: {
      just: '刚刚',
      min: '分钟前',
      hour: '小时前',
      day: '天前',
      month: '个月前',
    },
  };

  // required plugins (only load if needs)
  stellar.plugins = {
    jQuery: 'https://fastly.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js',
    sitesjs: '/js/plugins/sites.js',
    friendsjs: '/js/plugins/friends.js',
  };

  // optional plugins
  if ('false' == 'true') {
    stellar.plugins.lazyload = Object.assign({"enable":false,"js":"https://fastly.jsdelivr.net/npm/vanilla-lazyload@17.3.1/dist/lazyload.min.js","transition":"blur"});
  }
  if ('true' == 'true') {
    stellar.plugins.swiper = Object.assign({"enable":true,"css":"https://unpkg.com/swiper@6/swiper-bundle.min.css","js":"https://unpkg.com/swiper@6/swiper-bundle.min.js"});
  }
  if ('true' == 'true') {
    stellar.plugins.scrollreveal = Object.assign({"enable":true,"js":"https://fastly.jsdelivr.net/npm/scrollreveal@4.0.9/dist/scrollreveal.min.js","distance":"8px","duration":500,"interval":100,"scale":1});
  }
  if ('true' == 'true') {
    stellar.plugins.preload = Object.assign({"enable":true,"service":"flying_pages","instant_page":"https://fastly.jsdelivr.net/gh/volantis-x/cdn-volantis@4.1.2/js/instant_page.js","flying_pages":"https://fastly.jsdelivr.net/gh/gijo-varghese/flying-pages@2.1.2/flying-pages.min.js"});
  }
  if ('true' == 'true') {
    stellar.plugins.fancybox = Object.assign({"enable":true,"js":"https://fastly.jsdelivr.net/npm/@fancyapps/ui@4.0/dist/fancybox.umd.js","css":"https://fastly.jsdelivr.net/npm/@fancyapps/ui@4.0/dist/fancybox.css","selector":".swiper-slide img"});
  }
  if ('false' == 'true') {
    stellar.plugins.heti = Object.assign({"enable":false,"css":"https://unpkg.com/heti/umd/heti.min.css","js":"https://unpkg.com/heti/umd/heti-addon.min.js"});
  }
</script>

<!-- required -->

  
<script src="/js/main.js" async></script>



<!-- optional -->

  <script>
  function loadBeaudar() {
    const els = document.querySelectorAll("#comments #beaudar");
    if (els.length === 0) return;
    els.forEach((el, i) => {
      try {
        el.innerHTML = '';
      } catch (error) {
        console.log(error);
      }
      var script = document.createElement('script');
      script.src = 'https://beaudar.lipk.org/client.js';
      script.async = true;
      for (let key of Object.keys(el.attributes)) {
        let attr = el.attributes[key];
        if (['class', 'id'].includes(attr.name) === false) {
          script.setAttribute(attr.name, attr.value);
        }
      }
      el.appendChild(script);
    });
  }
  window.addEventListener('DOMContentLoaded', (event) => {
      loadBeaudar();
  });
</script>




<!-- inject -->

  
    <script src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js" type="text/javascript"></script> <script src="https://myhkw.cn/api/player/1660897650126" id="myhk" key="1660897650126" m="1"></script> <script src="https://cdn.bootcdn.net/ajax/libs/highlight.js/11.6.0/highlight.min.js"></script> <script src="//cdnjs.cloudflare.com/ajax/libs/highlightjs-line-numbers.js/2.8.0/highlightjs-line-numbers.min.js"></script> <script>hljs.highlightAll();hljs.initLineNumbersOnLoad();</script>
  


  </div>
<script>
            window.imageLazyLoadSetting = {
                isSPA: false,
                preloadRatio: 1,
                processImages: null,
            };
        </script><script>window.addEventListener("load",function(){var t=/\.(gif|jpg|jpeg|tiff|png)$/i,r=/^data:image\/[a-z]+;base64,/;Array.prototype.slice.call(document.querySelectorAll("img[data-original]")).forEach(function(a){var e=a.parentNode;"A"===e.tagName&&(e.href.match(t)||e.href.match(r))&&(e.href=a.dataset.original)})});</script><script>!function(n){n.imageLazyLoadSetting.processImages=o;var e=n.imageLazyLoadSetting.isSPA,i=n.imageLazyLoadSetting.preloadRatio||1,r=Array.prototype.slice.call(document.querySelectorAll("img[data-original]"));function o(){e&&(r=Array.prototype.slice.call(document.querySelectorAll("img[data-original]")));for(var t,a=0;a<r.length;a++)0<=(t=(t=r[a]).getBoundingClientRect()).bottom&&0<=t.left&&t.top<=(n.innerHeight*i||document.documentElement.clientHeight*i)&&function(){var t,e,n,i,o=r[a];t=o,e=function(){r=r.filter(function(t){return o!==t})},n=new Image,i=t.getAttribute("data-original"),n.onload=function(){t.src=i,e&&e()},t.src!==i&&(n.src=i)}()}o(),n.addEventListener("scroll",function(){var t,e;t=o,e=n,clearTimeout(t.tId),t.tId=setTimeout(function(){t.call(e)},500)})}(this);</script></body>
</html>
